# -*- coding: utf-8 -*-
"""pratica_1_estatistica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11MsJZwfKjvq6TU5Jx8v7dI03BKm0FLdt

# **ESTATÍSTICA 1 : FREQUÊNCIAS E MEDIDAS**
"""

##Bibliotecas base
import pandas as pd
import numpy as np
###bibliotecas para visualização de dados
import seaborn as sns
import matplotlib.pyplot as plt
###bibliotecas para estatística
import scipy.stats as stat

"""**Leitura de dados**"""

!pip install pydataset --quiet ##instala a biblioteca
from pydataset import data ###biblioteca que contém diversos datasets

"""Vamos, primeiramente, ler a documentação do dataset que iremos utilizar"""

data('Forbes2000', show_doc=True)

##leitura do dataset forbes que contém os dados a serem explorados
forbes = data ('Forbes2000')
forbes.head() #lista os 5 primeiros registros

"""**Tipos de variáveis**"""

forbes.info() ###verificando quais colunas são numéricas e quais são categóricas

"""No caso acima, as colunas com type 'object' são categóricas, as cols int64 assumem valores inteiros e as colunas float64 são numéricas contínuas.

# **ANÁLISE DE TENDÊNCIA CENTRAL**

Moda aplicável em todas as variáveis do dataframe
-utilizar a função df.mode()
-No caso vamos retirar as 2 primeiras cols, pois elas assumem valores úncios , são identificadores.
"""

forbes.iloc[:,2:8].mode() #moda considerando todas as linhas das cols 2  a  7

"""Média e mediana(somente para variáveis numéricas)"""

forbes[['sales','profits', 'assets', 'marketvalue']].mean()

forbes[['sales','profits', 'assets', 'marketvalue']].median() #comparar media e mediana para verificar existência de outliers

"""A função describe calcula estatísticas descritivas das variaveis numéricas (mais rápida). Nesse caso, temos a média e a mediana representadas pelo percentil 50%"""

forbes.describe()

"""# **ANÁLISE DE DISPERSÃO E OUTLIERS**

Análise de dispersão:
**1- AMPLITUDE, DESVIO PADRÃO E VARIÂNCIA**
"""

### essa função adiciona no describe anterior as cols de amplitude e variância
###a amplitude será o máximo-mínimo valor
###a variância será o desvio padrão ao quadrado
def describe_new(df):
  df1 = df.describe()
  df1.loc['amplitude'] =df1.loc['max'] - df1.loc['min']
  df1.loc['variancia'] = df1.loc['std'] * df1.loc['std']
  return df1

describe_new(forbes)

"""A maior amplitude ou discrepância das empresas listadas na forbes 2000, é relacionada aos ativos da empresa, os assets, conforme podemos ver. Essa também é a variável com maior desvio padrão (rank não é considerado por que é a classificação das empresas , funciona como um ID).

# **HISTOGRAMA DAS VARIÁVEIS**
"""

plt.rcParams['figure.figsize'] = [8,10]
sns.set_theme()
#create distplots
for column in forbes.select_dtypes(include=np.number).columns: #cria histogramas para as variáveis numéricas
  plt.figure()
  sns.displot(data=forbes, x = column, kde = True) #kde exibe a curva de densidade
  plt.title('Histograma:' +column)

"""há funções no python que já geram os histogramas automaticamente

# **BoxPlot**
"""

plt.rcParams['figure.figsize'] = [8,4]###para cada uma das cols numéricas roda o boxplot
sns.set_theme()
for column in forbes.select_dtypes(include=np.number).columns:
    plt.figure()
    sns.boxplot(data=forbes, x = column, color ='cyan', showfliers=True) #showfliers - se exibe ou nao os outliers
    plt.title('Bixplot: ' +column + 'in billion USD')

"""Nota-se a grande qtidade de outliers expressados pelos pontos nos gráficos de caixa, o que dificulta a visualização de dados. Para realizar boxplots, sem eles, pode-se rodar a mesma função, porem como o parâmetro showfliers = False. Facilitando a análise dos dados."""

plt.rcParams['figure.figsize'] = [8,4]###para cada uma das cols numéricas roda o boxplot
sns.set_theme()
for column in forbes.select_dtypes(include=np.number).columns:
    plt.figure()
    sns.boxplot(data=forbes, x = column, color ='cyan', showfliers=False) #showfliers - se exibe ou nao os outliers
    plt.title('Bixplot: ' +column + 'in billion USD')

"""Pelo boxes, podemos ver a grande concentração de empresas com:
1-vendas próximas a 2-9 bilhões
2-lucro oscilando próximo a 0(0.1 a 0.5 bilhões) com valores positivos e negativos nas caldas.
3- assets9ativos) 5 a 25 bilhões
4- valor de mercado próximo a 3-11 bilhões

# **ANÁLISE DOS OUTLIERS**

**1-MÉTODO DO Z SCORE**
O método z-score utiliza como referência qtos desvios padrões a info está na média. Se z-score >3 , desvios padrões geralmente se pode considerar um outlier.
"""

#precisa do pandas,numpy e do scipy(pacote de estatística) -contém a função z-score
def find_outlier_zscore(dataset,threshold,colname):
  ###função que calcula a quantidade de outliers encontrados dado o nome do dataframe, threshold e o nome da col
  df=dataset[colname]
  outliers = []
  zscore = []
  threshold = threshold
  mean = np.mean(df)
  std = np.std(df)
  for i in df.values:
    z_score = (i-mean)/std
    zscore.append(z_score)
    if np.abs(z_score) > threshold:
      outliers.append(i)
  print('O número de outliers encontrado em {} foi de: ' .format(colname), len(outliers))
  return zscore, outliers

import numpy as np
for column in forbes.select_dtypes(include=np.number).columns:
  zscore,out = find_outlier_zscore(forbes, 3, column)
  if len(out) > 0:
    plt.figure(figsize = (10,5))
    sns.displot(zscore)
    plt.axvspan(xmin = 3,xmax =max(zscore),alpha=0.2, color ='red')
    plt.title('outliers detectados em {}'.format(column))

"""pelo gra´fico acima fica mais fácil visualizar os valores outliers para cada nível de z-score. Vemos que para z-score =3, valores considerados outliers estão nas caldas dos histogramas, em vermelho.

# **REMOVENDO OUTLIERS COM O MÉTODO Z-SCORE**

1-REPLACE OUTLIERS WITH MEAN
"""

def replace_na_outlier_zscore(dataset, threshold, colname):
  ###função que faz um replace para NAN (valor nulo)caso seja encontrado um outlier
  df=dataset[colname]
  outliers = []
  zscore = []
  val = []
  threshold = threshold
  mean = np.mean(df)
  std = np.std(df)
  for i in df.values:
    z_score = (i- mean)/std
    zscore.append(z_score)
    if np.abs(z_score) > threshold:
      outliers.append(i)
      val.append(np.nan)
    else:
      val.append(i)
  return val

def drop_outliers(dataset, threshold):
  ###vamos utilizar a função drop NA para remover outliers
  for column in dataset.select_dtypes(include=np.number).columns:
    dataset[column] =  replace_na_outlier_zscore(dataset,3 ,column)
  return dataset.dropna()

def replace_median_outliers(dataset, threshold):
  ###vamos utilizar a função fillna para trocar os NANs pela medianas
  for column in dataset.select_dtypes(include=np.number).columns:
    dataset[column] =  replace_na_outlier_zscore(dataset,3 ,column)
  return dataset.fillna(dataset.median())

forbes_zscore_na = drop_outliers(forbes,3)

forbes_zscore_median = replace_median_outliers(forbes,3)

forbes_zscore_median

"""# **2-Método do IQR**

O método IQR (distância inter-quartil em inglês) vê a distãncia da amplitude dos quartis
"""

forbes = data('Forbes2000')

def find_outlier_iqr(dataset, colname):
  q25, q75 = np.quantile(dataset[colname], 0.25), np.quantile(dataset[colname], 0.75)
  #calcula IQR
  iqr = q75 - q25
  #calcula outlier cutoff
  cut_off = iqr * 1.5
  #calcula margens inferiores, lower e superiores upper
  lower, upper = q25 - cut_off, q75 + cut_off
  print('IQR é ', iqr)
  #print('valor mínimo', lower)
  #print('valor máximo', upper)
  outliers = []


  for i in dataset[colname].values:
    if((i > upper) or (i < lower)):
      outliers.append(i)
  print('o numero de outliers encontrado foi de', len(outliers))
  return lower, upper, outliers

for column in forbes.select_dtypes(include = np.number).columns:
  lower, upper, out = find_outlier_iqr(forbes, column)
  if (len(out) > 0):
    plt.figure(figsize = (10,6))
    sns.displot(forbes[column],kde = False)
    plt.axvspan(xmin = lower,xmax = forbes[column].min(), alpha=0.2, color='red')
    plt.axvspan(xmin = upper,xmax = forbes[column].max(), alpha=0.2, color='red')
    plt.title('Outliers detectados em {}' .format(column))

"""# **ANÁLISE DE MISSING VALUES (DADOS FALTANTES)**

1-vamos verificar a soma de dados faltantes para dada uma das cols do dataframe:
"""

#forbes.isna()  só aparce falses e trues
forbes.isna().sum()

import missingno as msno #pacote com visualizações de dados faltantes

msno.matrix(forbes)  #essa visualização nos dá uma ideia da completude dos dados faltantes, no caso aparece em profits(lucro), é o branco na col

"""Atenção: isna() é o mesmo que isnull(), no pandas


"""

###vamos construir uma tabela com o % de valores faltantes de cada variável abaixo
missing  = forbes.isna().sum()
missing_perc = 100 * forbes.isna().sum()/len(forbes)

mis_val_table  = pd.concat([missing,missing_perc], axis = 1)

mis_val_table = mis_val_table.rename(columns = {0:'# Count: valores nulos', 1: '% do Total'})


mis_val_table= mis_val_table[mis_val_table.iloc[:,1] != 0].sort_values('% do Total', ascending = False).round(1)


print('O dataframe contém ' + str(forbes.shape[1]) + ' colunas.\n'
        'contendo' + str(mis_val_table.shape[0]) +
        ' colunas com valores faltantes.')


mis_val_table

"""# **EDA AUTOMATIZADA**

Existem 2 pacote famosos no mundo da análise de dados que fazem análises exploratórias automatizadas:
1- pandas profiling - chamado atualmente de ydataprofiling
2-Sweetviz
Ambas geram relatórios html prontos para análises / interpretações do analista
"""

!pip install sweetviz  --quiet

import sweetviz as sv
my_report   = sv.analyze(forbes) #lê os dados e cria uma report

my_report.show_notebook() ### para ver o html dos graficos gerados no próprio notebook, resume dados

my_report.show_html(filepath='./SWEETVIZ_REPORT.html',
                    open_browser =True,
                    layout='widescreen',
                    scale=None)
###gera o html e salva no seu diretório local